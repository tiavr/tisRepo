
2 HISTOGRAMMES DANS LA MEME FENETRE
> par(mfrow=c(2,1))

TAILLE ET PAS DE L'HIST
> tailles.breaks <- seq(145, 205, 2)

CREATION DE l'HIST
> hist(d.f, col="pink", breaks=tailles.breaks)
> hist(d.h, col="darkblue", breaks=tailles.breaks)

RECUPERATION DES TAILLES HOMME ET FEMMES
d.h <- d.s[d.s$Sexe=="H", 2]
d.f <- d.s[d.s$Sexe=="F", 2]

REPRESENTATION QUANTILE 

> qqnorm(d.f, col="pink", pch=20)
> qqline(d.f, col="red")
> qqnorm(d.h, col="blue", pch=20)
> qqline(d.h, col="red")
> 

TEST DE SHAPIRO-WILK
shapiro.test(d.h) 
Hypothèse : les 2 distributions sont égales (femmes et loi normale)
p-value : Probabilité que la mesure soit due au hasard.

Pour les femmes : p-value < 0.05 donc elle ne suit pas une loi normale
Pour les hommes : p-value > 0.05

Test de student : 

Sert à comparer les moyennes
Mais la moyenne est paramètre d'une loi normale, or la distribution des femmes ne suit pas une loi normale.

> t.test(d.f, d.h, var.equal=T)

        Two Sample t-test

data:  d.f and d.h
t = -21.639, df = 406, p-value < 2.2e-16
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -15.13257 -12.61211
sample estimates:
mean of x mean of y 
 165.5755  179.4479 

 p-value < 0.05 (probabilité que l'écart entre les 2 populations soit due au hasard)
 Donc il est peu probable car p-value < 0.05.


Test var.test(d.h, d.f) : 
> var.test(d.h, d.f)

        F test to compare two variances

data:  d.h and d.f
F = 1.276, num df = 162, denom df = 244, p-value = 0.08541
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.9666089 1.6981920
sample estimates:
ratio of variances 
          1.276015 


les variances sont acceptablement homongenes


Test de wilcox :
wilcox.test(d.f, d.h)

C'est un test de rang : Il faut ranger dans l'ordre croissant les tailles puis on attribut des rangs de 1 a n à ces tailles.

      Wilcoxon rank sum test with continuity correction

data:  d.f and d.h
W = 2278.5, p-value < 2.2e-16
alternative hypothesis: true location shift is not equal to 0

on a p-value < 0.05
Donc peu probable que l'ecart des rang est du au hasard
Donc il y a un ecart des rangs significatifs entre les hommes et les femmes.

TEST UNILATERAL : 
On determine une hypothèse alternative qui se traduit en hypothèse d'égalité.

Hyp1 : MoyF < MoyH --> ce que je veux montrer
Hyp0 : 

Exemple : t.test(d.f, d.h, var.equal=T, alternative="less")

Test du Chi-2 : 

> e$Pointure <- cut(e$Pointure, breaks=c(-Inf, 39, 41, +Inf), labels=c('p', 'm', 'g'))
> e$Ecartement_Orbital <- cut(e$Ecartement_Orbital, breaks=c(-Inf, 6.271, +Inf), labels=c('-', '+'))
> head(e, 3)
   Pointure Ecartement_Orbital
8         m                  -
39        g                  -
41        p                  -
> head(e, 6)
    Pointure Ecartement_Orbital
8          m                  -
39         g                  -
41         p                  -
98         g                  +
100        m                  +
101        p                  -
> chisq.test(e$Pointure, e$Ecartement_Orbital)

        Pearson's Chi-squared test

data:  e$Pointure and e$Ecartement_Orbital
X-squared = 19.452, df = 2, p-value = 5.971e-05

Sample permet de prendre un échantillon :

sample(1:300, 10) ---> de 1 à 300 on prend que 10 echantillons

> p <- vector(mode = "numeric")
> for(i in 1:200){
+ e <- d[ sample(1:285,100),]
+ test <- chisq.test(e$Pointure, e$Ecartement_Orbital)
+ p[i] <- test$p.value
+ }

Boostrap : 

sample(1:285, 285, replace=T)
Replace = avec remise et 
meme nombre de personne pour l'echantillonnage : 285 = boostrap

si il est inférieur a 285 c'est le Jackknife

> p <- vector(mode = "numeric")
> for(i in 1:200){
+ e <- d[ sample(1:285,100),]
+ test <- chisq.test(e$Pointure, e$Taille_en_cm)
+ p[i] <- test$p.value
+ }

DEBUT DE COURS REGRESSION LIN

d <- d[ , 6:7] : Recupération des colonnes 6 et 7.

d <- na.omit(d) : Enlever les na.
summary(d)
plot(d)
plot(x=d$Taille_en_cm, y=d$Pointure, xlab="Taille (cm)", ylab="Pointure", pch=20)
Graphique qui montre pour chaque pointure les differentes tailles.

S'il n'y a pas corrélation : y = B0 + o * x soit B1 = 0.
La droite est horizontale.

rappel : y = B0 + B1x

Il y a des variations inter-individuelles : Pour une personne qui fait 1m70, ca va du 38 au 43 en pointure.

m1 <- with(d, lm(Pointure ~ Taille_en_cm))
summary(m1)
R-squared : 75% des données connues donc très bon modèle

F-Statistic : Bon Rapprt signal sur bruit
P-value < 0.05 et très faible
Conclusion : très bon modèle


Coefficients : 
Intercept : ordonnée à l'origine
Donc l'équation c'est : -4.4 + 0.26x

Traçage de la droite : abline(m1, col='red') qui enlève toute variation inter-individuelles : une seule pointure pour une seule taille.

R2 = sig2 fac / sig2 fac + sig2 res
sig2 tot = sig2 res + sig2 fac

cov(d) = covariance
cor(d) = correlation

cor.test(d$Taille_en_cm, d$Longueur_Majeur) 

Sample : 

id <- sample(1:307, 20)
d.s <- d[id,]
points(d.s$Taille_en_cm, d.s$Longueur_Majeur, col="blue", pch=20)
m1 <- lm(d.s$Longueur_Majeur ~ d.s$Taille_en_cm)
summary(m1)
abline(m1, col="blue")